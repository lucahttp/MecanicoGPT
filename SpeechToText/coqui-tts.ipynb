{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TTS\n",
      "  Using cached TTS-0.14.0.tar.gz (1.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting gruut[de,es,fr]==2.2.3\n",
      "  Using cached gruut-2.2.3.tar.gz (73 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch>=1.7\n",
      "  Using cached torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "Collecting scipy>=1.4.0\n",
      "  Using cached scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "Collecting trainer==0.0.20\n",
      "  Using cached trainer-0.0.20-py3-none-any.whl (45 kB)\n",
      "Collecting unidic-lite==1.0.8\n",
      "  Using cached unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bangla==0.0.2\n",
      "  Using cached bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 8.8 MB/s eta 0:00:00\n",
      "Collecting pysbd\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: flask in c:\\python310\\lib\\site-packages (from TTS) (2.2.2)\n",
      "Collecting coqpit>=0.0.16\n",
      "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting librosa==0.10.0.*\n",
      "  Using cached librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "Collecting k-diffusion\n",
      "  Using cached k_diffusion-0.0.15-py3-none-any.whl (25 kB)\n",
      "Collecting cython==0.29.28\n",
      "  Using cached Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Collecting fsspec>=2021.04.0\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Collecting umap-learn==0.5.1\n",
      "  Using cached umap-learn-0.5.1.tar.gz (80 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.1-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "Collecting mecab-python3==1.0.5\n",
      "  Using cached mecab_python3-1.0.5-cp310-cp310-win_amd64.whl (500 kB)\n",
      "Collecting bnnumerizer\n",
      "  Using cached bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting inflect==5.6.0\n",
      "  Using cached inflect-5.6.0-py3-none-any.whl (33 kB)\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 19.2/19.2 MB 4.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting bnunicodenormalizer==0.1.1\n",
      "  Using cached bnunicodenormalizer-0.1.1.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "Collecting g2pkk>=0.1.1\n",
      "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
      "Collecting pypinyin\n",
      "  Using cached pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting anyascii\n",
      "  Using cached anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "Collecting numba==0.56.4\n",
      "  Using cached numba-0.56.4-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from TTS) (23.1)\n",
      "Collecting jamo\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Collecting Babel<3.0.0,>=2.8.0\n",
      "  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
      "     --------------------------------------- 10.1/10.1 MB 58.8 MB/s eta 0:00:00\n",
      "Collecting dateparser~=1.1.0\n",
      "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
      "     ------------------------------------- 293.8/293.8 kB 17.7 MB/s eta 0:00:00\n",
      "Collecting gruut-ipa<1.0,>=0.12.0\n",
      "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
      "     -------------------------------------- 101.6/101.6 kB 6.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gruut_lang_en~=2.0.0\n",
      "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
      "     --------------------------------------- 15.2/15.2 MB 12.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jsonlines~=1.2.0\n",
      "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting networkx<3.0.0,>=2.5.0\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 65.0 MB/s eta 0:00:00\n",
      "Collecting num2words<1.0.0,>=0.5.10\n",
      "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "     ---------------------------------------- 125.2/125.2 kB ? eta 0:00:00\n",
      "Collecting python-crfsuite~=0.9.7\n",
      "  Downloading python_crfsuite-0.9.9-cp310-cp310-win_amd64.whl (139 kB)\n",
      "     ---------------------------------------- 139.4/139.4 kB ? eta 0:00:00\n",
      "Collecting gruut_lang_fr~=2.0.0\n",
      "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
      "     --------------------------------------- 10.9/10.9 MB 12.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gruut_lang_es~=2.0.0\n",
      "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
      "     ---------------------------------------- 31.4/31.4 MB 6.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gruut_lang_de~=2.0.0\n",
      "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
      "     ---------------------------------------- 18.1/18.1 MB 9.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.3.5-cp310-cp310-win_amd64.whl (184 kB)\n",
      "     ------------------------------------- 184.0/184.0 kB 10.9 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4.1.1\n",
      "  Downloading typing_extensions-4.6.2-py3-none-any.whl (31 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "     ------------------------------------- 377.0/377.0 kB 22.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from librosa==0.10.0.*->TTS) (5.1.1)\n",
      "Collecting joblib>=0.14\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ---------------------------------------- 298.0/298.0 kB ? eta 0:00:00\n",
      "Collecting msgpack>=1.0\n",
      "  Downloading msgpack-1.0.5-cp310-cp310-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.6/61.6 kB ? eta 0:00:00\n",
      "Collecting pooch<1.7,>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.3/56.3 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting scikit-learn>=0.20.0\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "     ---------------------------------------- 8.3/8.3 MB 58.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from numba==0.56.4->TTS) (58.1.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp310-cp310-win_amd64.whl (23.2 MB)\n",
      "     ---------------------------------------- 23.2/23.2 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     --------------------------------------- 14.6/14.6 MB 59.8 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "     ------------------------------------- 895.7/895.7 kB 55.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from trainer==0.0.20->TTS) (5.9.5)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "     ---------------------------------------- 114.5/114.5 kB ? eta 0:00:00\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 75.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cffi>=1.0\n",
      "  Downloading cffi-1.15.1-cp310-cp310-win_amd64.whl (179 kB)\n",
      "     ------------------------------------- 179.1/179.1 kB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\python310\\lib\\site-packages (from torch>=1.7->TTS) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 61.6 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "     ---------------------------------------- 97.1/97.1 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 kB ? eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Requirement already satisfied: click>=8.0 in c:\\python310\\lib\\site-packages (from flask->TTS) (8.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\python310\\lib\\site-packages (from flask->TTS) (2.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\python310\\lib\\site-packages (from flask->TTS) (2.2.2)\n",
      "Collecting clean-fid\n",
      "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
      "Collecting resize-right\n",
      "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 42.8 MB/s eta 0:00:00\n",
      "Collecting kornia\n",
      "  Downloading kornia-0.6.12-py2.py3-none-any.whl (653 kB)\n",
      "     ------------------------------------- 653.4/653.4 kB 42.9 MB/s eta 0:00:00\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.5.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting torchsde\n",
      "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
      "     ---------------------------------------- 59.2/59.2 kB ? eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 38.2 MB/s eta 0:00:00\n",
      "Collecting jsonmerge\n",
      "  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting clip-anytorch\n",
      "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 43.9 MB/s eta 0:00:00\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "     ------------------------------------- 219.1/219.1 kB 13.1 MB/s eta 0:00:00\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-win_amd64.whl (23.7 MB)\n",
      "     --------------------------------------- 23.7/23.7 MB 34.4 MB/s eta 0:00:00\n",
      "Collecting torchdiffeq\n",
      "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
      "     -------------------------------------- 163.0/163.0 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.3/98.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->TTS) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.3/55.3 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 32.3 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.5.5-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     ------------------------------------- 267.9/267.9 kB 17.2 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "     ------------------------------------- 502.3/502.3 kB 32.8 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ------------------------------------- 341.8/341.8 kB 22.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->TTS) (0.4.5)\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 44.3 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ---------------------------------------- 224.5/224.5 kB ? eta 0:00:00\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 118.7/118.7 kB ? eta 0:00:00\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch>=1.7->TTS) (2.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
      "Collecting docopt>=0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 123.2/123.2 kB ? eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.5/61.5 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "     -------------------------------------- 157.0/157.0 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.1/53.1 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting jsonschema>2.4.0\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 44.2 MB/s eta 0:00:00\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
      "     ------------------------------------- 219.4/219.4 kB 13.1 MB/s eta 0:00:00\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.29.0-py3-none-any.whl (3.4 MB)\n",
      "     ---------------------------------------- 3.4/3.4 MB 43.1 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 536.2/536.2 kB ? eta 0:00:00\n",
      "Collecting boltons>=20.2.1\n",
      "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
      "     ------------------------------------- 194.8/194.8 kB 12.3 MB/s eta 0:00:00\n",
      "Collecting trampoline>=0.1.2\n",
      "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\n",
      "     ---------------------------------------- 206.5/206.5 kB ? eta 0:00:00\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-win_amd64.whl (11 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ------------------------------------- 184.3/184.3 kB 10.9 MB/s eta 0:00:00\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.19.3-cp310-cp310-win_amd64.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "     -------------------------------------- 143.1/143.1 kB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\lucas\\appdata\\roaming\\python\\python310\\site-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: TTS\n",
      "  Building wheel for TTS (pyproject.toml): started\n",
      "  Building wheel for TTS (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for TTS: filename=TTS-0.14.0-cp310-cp310-win_amd64.whl size=736644 sha256=9e9c8ede9f463f288f9e37f01440bf5b3239277f8467c24c53455f86b448c2c6\n",
      "  Stored in directory: c:\\users\\lucas\\appdata\\local\\pip\\cache\\wheels\\ae\\ca\\66\\0d6bc8e93d2f0de9c739857509063aadd3f16b68ee85a1f571\n",
      "Successfully built TTS\n",
      "Installing collected packages: unidic-lite, trampoline, tokenizers, resize-right, pytz, python-crfsuite, pathtools, msgpack, mpmath, mecab-python3, jieba, jamo, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, boltons, bnunicodenormalizer, bnnumerizer, bangla, appdirs, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, smmap, setproctitle, regex, pyyaml, pysbd, pyrsistent, pypinyin, pyparsing, pycparser, protobuf, Pillow, numpy, num2words, networkx, multidict, llvmlite, lazy-loader, kiwisolver, jsonlines, joblib, inflect, idna, gruut-ipa, ftfy, fsspec, frozenlist, fonttools, filelock, einops, docker-pycreds, cython, cycler, coqpit, charset-normalizer, certifi, Babel, audioread, attrs, async-timeout, anyascii, yarl, tzlocal, torch, tifffile, tensorboardX, soxr, sentry-sdk, scipy, requests, PyWavelets, pandas, numba, nltk, jsonschema, imageio, gitdb, contourpy, cffi, aiosignal, torchvision, torchsde, torchdiffeq, torchaudio, soundfile, scikit-learn, scikit-image, pooch, matplotlib, kornia, jsonmerge, huggingface-hub, GitPython, g2pkk, dateparser, aiohttp, accelerate, wandb, transformers, trainer, pynndescent, librosa, gruut, clip-anytorch, clean-fid, umap-learn, k-diffusion, TTS\n",
      "  Running setup.py install for unidic-lite: started\n",
      "  Running setup.py install for unidic-lite: finished with status 'done'\n",
      "  Running setup.py install for pathtools: started\n",
      "  Running setup.py install for pathtools: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "  DEPRECATION: unidic-lite is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  DEPRECATION: pathtools is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python310\\\\Scripts\\\\mecab-py.exe' -> 'C:\\\\Python310\\\\Scripts\\\\mecab-py.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > Downloading model to C:\\Users\\lucas\\AppData\\Local\\tts\\tts_models--multilingual--multi-dataset--your_tts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 425M/425M [00:14<00:00, 30.0MiB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CC BY-NC-ND 4.0\n",
      " > Check https://creativecommons.org/licenses/by-nc-nd/4.0/ for more info.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "['This is a test!', 'This is also a test!!']\n",
      " > Processing time: 1.2980012893676758\n",
      " > Real-time factor: 0.2916856830039721\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 0.39799928665161133\n",
      " > Real-time factor: 0.25366429996915957\n",
      " > Downloading model to C:\\Users\\lucas\\AppData\\Local\\tts\\tts_models--de--thorsten--tacotron2-DDC\n",
      " > Model's license - apache 2.0\n",
      " > Check https://choosealicense.com/licenses/apache-2.0/ for more info.\n",
      " > Downloading model to C:\\Users\\lucas\\AppData\\Local\\tts\\vocoder_models--de--thorsten--hifigan_v1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m tts\u001b[39m.\u001b[39mtts_to_file(text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHello world!\u001b[39m\u001b[39m\"\u001b[39m, speaker\u001b[39m=\u001b[39mtts\u001b[39m.\u001b[39mspeakers[\u001b[39m0\u001b[39m], language\u001b[39m=\u001b[39mtts\u001b[39m.\u001b[39mlanguages[\u001b[39m0\u001b[39m], file_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Running a single speaker model\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39m# Init TTS with the target model name\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m tts \u001b[39m=\u001b[39m TTS(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtts_models/de/thorsten/tacotron2-DDC\u001b[39;49m\u001b[39m\"\u001b[39;49m, progress_bar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, gpu\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Run TTS\u001b[39;00m\n\u001b[0;32m     21\u001b[0m tts\u001b[39m.\u001b[39mtts_to_file(text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIch bin eine Testnachricht.\u001b[39m\u001b[39m\"\u001b[39m, file_path\u001b[39m=\u001b[39mOUTPUT_PATH)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\TTS\\api.py:285\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[1;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtts_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcoqui_studio\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[1;32m--> 285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_tts_model_by_name(model_name, gpu)\n\u001b[0;32m    286\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvoice_conversion_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[0;32m    287\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\TTS\\api.py:381\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[1;34m(self, model_name, gpu)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsapi \u001b[39m=\u001b[39m CS_API()\n\u001b[0;32m    380\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_model_by_name(\n\u001b[0;32m    382\u001b[0m         model_name\n\u001b[0;32m    383\u001b[0m     )\n\u001b[0;32m    385\u001b[0m     \u001b[39m# init synthesizer\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[39m# None values are fetch from the model\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynthesizer \u001b[39m=\u001b[39m Synthesizer(\n\u001b[0;32m    388\u001b[0m         tts_checkpoint\u001b[39m=\u001b[39mmodel_path,\n\u001b[0;32m    389\u001b[0m         tts_config_path\u001b[39m=\u001b[39mconfig_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m         use_cuda\u001b[39m=\u001b[39mgpu,\n\u001b[0;32m    398\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\TTS\\api.py:351\u001b[0m, in \u001b[0;36mTTS.download_model_by_name\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m model_item\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdefault_vocoder\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[39mreturn\u001b[39;00m model_path, config_path, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m vocoder_path, vocoder_config_path, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanager\u001b[39m.\u001b[39;49mdownload_model(model_item[\u001b[39m\"\u001b[39;49m\u001b[39mdefault_vocoder\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    352\u001b[0m \u001b[39mreturn\u001b[39;00m model_path, config_path, vocoder_path, vocoder_config_path, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\TTS\\utils\\manage.py:278\u001b[0m, in \u001b[0;36mModelManager.download_model\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_model_files(model_item[\u001b[39m\"\u001b[39m\u001b[39mgithub_rls_url\u001b[39m\u001b[39m\"\u001b[39m], output_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar)\n\u001b[0;32m    277\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 278\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_zip_file(model_item[\u001b[39m\"\u001b[39;49m\u001b[39mgithub_rls_url\u001b[39;49m\u001b[39m\"\u001b[39;49m], output_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogress_bar)\n\u001b[0;32m    279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_model_license(model_item\u001b[39m=\u001b[39mmodel_item)\n\u001b[0;32m    280\u001b[0m \u001b[39m# find downloaded files\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\TTS\\utils\\manage.py:405\u001b[0m, in \u001b[0;36mModelManager._download_zip_file\u001b[1;34m(file_url, output_folder, progress_bar)\u001b[0m\n\u001b[0;32m    403\u001b[0m temp_zip_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, file_url\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m    404\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(temp_zip_name, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m--> 405\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(block_size):\n\u001b[0;32m    406\u001b[0m         \u001b[39mif\u001b[39;00m progress_bar:\n\u001b[0;32m    407\u001b[0m             progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[1;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[0;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\urllib3\\response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[0;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# Running a multi-speaker and multi-lingual model\n",
    "\n",
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "tts = TTS(model_name)\n",
    "# Run TTS\n",
    "# ‚ùó Since this model is multi-speaker and multi-lingual, we must set the target speaker and the language\n",
    "# Text to speech with a numpy output\n",
    "wav = tts.tts(\"This is a test! This is also a test!!\", speaker=tts.speakers[0], language=tts.languages[0])\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\", speaker=tts.speakers[0], language=tts.languages[0], file_path=\"output.wav\")\n",
    "\n",
    "# Running a single speaker model\n",
    "\n",
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)\n",
    "\n",
    "# Example voice cloning with YourTTS in English, French and Portuguese:\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False, gpu=True)\n",
    "tts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"Isso √© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")\n",
    "\n",
    "\n",
    "# Example voice conversion converting speaker of the `source_wav` to the speaker of the `target_wav`\n",
    "\n",
    "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=True)\n",
    "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")\n",
    "\n",
    "# Example voice cloning by a single speaker TTS model combining with the voice conversion model. This way, you can\n",
    "# clone voices by using any model in üê∏TTS.\n",
    "\n",
    "tts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\n",
    "tts.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"ouptut.wav\"\n",
    ")\n",
    "\n",
    "# Example text to speech using [üê∏Coqui Studio](https://coqui.ai) models. You can use all of your available speakers in the studio.\n",
    "# [üê∏Coqui Studio](https://coqui.ai) API token is required. You can get it from the [account page](https://coqui.ai/account).\n",
    "# You should set the `COQUI_STUDIO_TOKEN` environment variable to use the API token.\n",
    "\n",
    "# If you have a valid API token set you will see the studio speakers as separate models in the list.\n",
    "# The name format is coqui_studio/en/<studio_speaker_name>/coqui_studio\n",
    "models = TTS().list_models()\n",
    "# Init TTS with the target studio speaker\n",
    "tts = TTS(model_name=\"coqui_studio/en/Torcull Diarmuid/coqui_studio\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH)\n",
    "# Run TTS with emotion and speed control\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH, emotion=\"Happy\", speed=1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
